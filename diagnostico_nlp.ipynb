{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrosof/CardioAI--Classificador/blob/main/diagnostico_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzm-nz-ymrs1"
      },
      "source": [
        "# CardioIA – Parte 1: Extração de sintomas e sugestão de diagnósticos\n",
        "\n",
        "Este notebook:\n",
        "1. Lê um arquivo **.txt** com 10 frases de pacientes.\n",
        "2. Lê o **mapa de conhecimento** (CSV) com pares de sintomas → doença associada.\n",
        "3. Normaliza texto (minúsculas, sem acentos, sem pontuação).\n",
        "4. Extrai sintomas por **casamento de expressões** (substrings/regex simples).\n",
        "5. Gera um ranking de diagnósticos sugeridos por frase e salva a saída em CSV.\n",
        "\n",
        "> **Atenção:** Tratamento **didático**. Não é ferramenta clínica."
      ],
      "id": "Rzm-nz-ymrs1"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "7AlCfjiomurC",
        "outputId": "a969868e-8820-4914-874f-739e3b90d5cf"
      },
      "id": "7AlCfjiomurC",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3329394316.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQK-DTPrmrs3",
        "outputId": "d2aa146d-3719-4c59-f74d-ed78e1a113da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR   = /content/drive/MyDrive/CardioAI/Classificador/data\n",
            "REPORTS_DIR = /content/drive/MyDrive/CardioAI/Classificador/reports\n",
            "TXT_FRASES = /content/drive/MyDrive/CardioAI/Classificador/data/sintomas_10frases.txt\n",
            "CSV_MAPA   = /content/drive/MyDrive/CardioAI/Classificador/data/mapa_sintomas.csv\n",
            "CSV_SAIDA  = /content/drive/MyDrive/CardioAI/Classificador/reports/diagnosticos_preditos.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Caminhos base no Google Drive\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/CardioAI/Classificador\")\n",
        "\n",
        "# Subpastas dentro do diretório do projeto\n",
        "DATA_DIR = BASE_DIR / \"data\"\n",
        "REPORTS_DIR = BASE_DIR / \"reports\"\n",
        "\n",
        "# Arquivos de entrada e saída\n",
        "TXT_FRASES = DATA_DIR / \"sintomas_10frases.txt\"\n",
        "CSV_MAPA = DATA_DIR / \"mapa_sintomas.csv\"\n",
        "CSV_SAIDA = REPORTS_DIR / \"diagnosticos_preditos.csv\"\n",
        "\n",
        "# Criação das pastas (somente reports, já que data deve existir)\n",
        "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"DATA_DIR   = {DATA_DIR}\")\n",
        "print(f\"REPORTS_DIR = {REPORTS_DIR}\")\n",
        "print(f\"TXT_FRASES = {TXT_FRASES}\")\n",
        "print(f\"CSV_MAPA   = {CSV_MAPA}\")\n",
        "print(f\"CSV_SAIDA  = {CSV_SAIDA}\")"
      ],
      "id": "dQK-DTPrmrs3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q08MvqSSmrs4"
      },
      "execution_count": 3,
      "outputs": [],
      "source": [
        "def remover_acentos(txt: str) -> str:\n",
        "    nfkd = unicodedata.normalize(\"NFKD\", txt)\n",
        "    return \"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
        "\n",
        "def normalizar(txt: str) -> str:\n",
        "    # minúsculas, remove acentos e pontuação simples\n",
        "    txt = txt.lower()\n",
        "    txt = remover_acentos(txt)\n",
        "    # troca pontuação por espaço\n",
        "    txt = re.sub(r'[\\.,;:!?\\-/()\\[\\]{}\"]+', \" \", txt)\n",
        "    # normaliza múltiplos espaços\n",
        "    txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
        "    return txt\n",
        "\n",
        "def contem_expressao(frase_norm: str, expressao_norm: str) -> bool:\n",
        "    # busca por substring com margens de palavra aproximadas quando possível\n",
        "    # se a expressao tiver espaços, busca substring simples\n",
        "    if \" \" in expressao_norm:\n",
        "        return expressao_norm in frase_norm\n",
        "    # caso seja uma palavra única, usar limites de palavra\n",
        "    return re.search(rf\"\\b{re.escape(expressao_norm)}\\b\", frase_norm) is not None"
      ],
      "id": "q08MvqSSmrs4"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/CardioAI/Classificador/reports\"\n"
      ],
      "metadata": {
        "id": "6mniA7imoRUI"
      },
      "id": "6mniA7imoRUI",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "97dR4neHmrs6",
        "outputId": "e6d4d34b-2696-4bd4-c781-fc382ef99cd6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/CardioAI/Classificador/data/mapa_sintomas.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2562784959.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Carregando o mapa e as frases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmapa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_MAPA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTXT_FRASES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlinhas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mln\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CardioAI/Classificador/data/mapa_sintomas.csv'"
          ]
        }
      ],
      "source": [
        "# Carregando o mapa e as frases\n",
        "mapa = pd.read_csv(CSV_MAPA)\n",
        "with open(TXT_FRASES, \"r\", encoding=\"utf-8\") as f:\n",
        "    linhas = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
        "\n",
        "print(\"Exemplo do mapa (5 primeiras linhas):\")\n",
        "display(mapa.head())\n",
        "\n",
        "print(\"\\nFrases (detectadas):\")\n",
        "for i, ln in enumerate(linhas, 1):\n",
        "    print(f\"{i}. {ln}\")"
      ],
      "id": "97dR4neHmrs6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxXnh3yqmrs6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Prepara expressões normalizadas do mapa para facilitar matching\n",
        "mapa_proc = []\n",
        "for _, row in mapa.iterrows():\n",
        "    s1 = normalizar(str(row[\"sintoma_1\"]))\n",
        "    s2 = normalizar(str(row[\"sintoma_2\"]))\n",
        "    doenca = str(row[\"doenca_associada\"]).strip()\n",
        "    if s1:\n",
        "        mapa_proc.append((s1, doenca))\n",
        "    if s2:\n",
        "        mapa_proc.append((s2, doenca))\n",
        "\n",
        "# Dicionário: expressao_norm -> set(doencas)\n",
        "from collections import defaultdict\n",
        "expressao_to_doencas = defaultdict(set)\n",
        "for expr, dz in mapa_proc:\n",
        "    expressao_to_doencas[expr].add(dz)\n",
        "\n",
        "len(expressao_to_doencas), list(list(expressao_to_doencas.items())[:5])"
      ],
      "id": "AxXnh3yqmrs6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBHIsBZCmrs6"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def sugerir_diagnosticos(frase: str, expressao_map: dict, top_k=3):\n",
        "    frase_norm = normalizar(frase)\n",
        "    matches = []\n",
        "    score = {}\n",
        "\n",
        "    # Verifica cada expressao do mapa na frase\n",
        "    for expr, doencas in expressao_map.items():\n",
        "        if contem_expressao(frase_norm, expr):\n",
        "            matches.append(expr)\n",
        "            for dz in doencas:\n",
        "                score[dz] = score.get(dz, 0) + 1  # soma 1 por match de expressão\n",
        "\n",
        "    # Ordena por pontuação decrescente e alfabética como tie-break\n",
        "    rank = sorted(score.items(), key=lambda x: (-x[1], x[0]))\n",
        "    sugestoes = [dz for dz, sc in rank[:top_k]]\n",
        "    return {\n",
        "        \"frase\": frase,\n",
        "        \"frase_norm\": frase_norm,\n",
        "        \"matches\": matches,\n",
        "        \"diagnosticos_rankeados\": rank,\n",
        "        \"sugestoes_topk\": sugestoes\n",
        "    }\n",
        "\n",
        "resultados = [sugerir_diagnosticos(fr, expressao_to_doencas, top_k=3) for fr in linhas]\n",
        "\n",
        "# Mostra alguns resultados\n",
        "for i, r in enumerate(resultados, 1):\n",
        "    print(\"=\"*80)\n",
        "    print(f\"[{i}] {r['frase']}\")\n",
        "    print(f\"Matches: {', '.join(r['matches']) if r['matches'] else '(nenhum)'}\")\n",
        "    if r[\"diagnosticos_rankeados\"]:\n",
        "        print(\"Diagnósticos sugeridos (doença:score):\")\n",
        "        for dz, sc in r[\"diagnosticos_rankeados\"]:\n",
        "            print(f\" - {dz}: {sc}\")\n",
        "        print(f\"TOP: {r['sugestoes_topk']}\")\n",
        "    else:\n",
        "        print(\"Nenhum diagnóstico sugerido com base no mapa.\")"
      ],
      "id": "kBHIsBZCmrs6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecp0G2NWmrs7"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Exporta uma tabela consolidada com resultados\n",
        "linhas_out = []\n",
        "for r in resultados:\n",
        "    linhas_out.append({\n",
        "        \"frase\": r[\"frase\"],\n",
        "        \"matches_encontrados\": \"; \".join(r[\"matches\"]),\n",
        "        \"doencas_sugeridas_top3\": \"; \".join(r[\"sugestoes_topk\"]) if r[\"sugestoes_topk\"] else \"\"\n",
        "    })\n",
        "\n",
        "df_out = pd.DataFrame(linhas_out, columns=[\"frase\", \"matches_encontrados\", \"doencas_sugeridas_top3\"])\n",
        "df_out.to_csv(CSV_SAIDA, index=False, encoding=\"utf-8\")\n",
        "print(f\"Arquivo gerado: {CSV_SAIDA.resolve()}\")\n",
        "display(df_out)"
      ],
      "id": "Ecp0G2NWmrs7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAjOfzPbmrs7"
      },
      "source": [
        "## Observações e próximos passos\n",
        "\n",
        "- Ajuste/expanda o **mapa de sintomas** para melhorar cobertura e precisão.\n",
        "- Adapte as **regras de pontuação** (e.g., peso maior para certas expressões como “dor no peito + suor frio”).\n",
        "- Integre com a **Parte 2** (classificador de risco) para gerar, além do diagnóstico sugerido, um **rótulo de risco**.\n",
        "- Reforce no README: uso **didático**, não clínico."
      ],
      "id": "OAjOfzPbmrs7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}